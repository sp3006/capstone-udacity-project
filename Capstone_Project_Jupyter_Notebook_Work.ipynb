{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "<h1> Udacity Guided Project : I94 immigration, Temprature and Airport data analysis <\\h1>\n",
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "--describe your project at a high level--\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### <h4> <br>Step 1: Scope the Project and Gather Data</br> </h4>\n",
    "<h4><br>Scope </br>\n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? </br></h4>\n",
    "##### In this project I will be using pyspark and python plotly on the I94 in order to data ingest, arrange, clean, prepare, analyze & visualize the trends in the data<\n",
    "<br>\n",
    "##### <h4> Describe and Gather Data </h4>\n",
    "##### <br>Describe the data sets you're using. Where did it come from? What type of information is included?  </br>\n",
    "\n",
    "##### i94 Immigration Sample Data : sample data which is from the US National Tourism and Trade Office. This data comes from the US National Tourism and Trade Office. This table is used for the fact table in this project.\n",
    "\n",
    "##### World Temperature Data world_temperature. This dataset contains temperature data of various cities from 1700’s – 2013. This dataset came from Kaggle. This table is not used because the data is available until 2013\n",
    "\n",
    "##### U.S. City Demographic Data us-cities-demographics. This dataset contains population details of all US Cities and census-designated places includes gender & race information. This data came from OpenSoft. The table is grouped by state to get aggregated statistics.\n",
    "\n",
    "##### Airport Codes is a simple table of airport codes and corresponding cities. The rows where IATA codes are available in the table are selected for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import configparser\n",
    "import datetime as dt\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.functions import isnan, when, count, col, udf, dayofmonth, dayofweek, month, year, weekofyear\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Row\n",
    "\n",
    "from pyspark.sql.functions import date_add as d_add\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import year, month, dayofmonth, weekofyear, date_format\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import requests\n",
    "import urllib.request\n",
    "requests.packages.urllib3.disable_warnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create configparser Object\n",
    "config = configparser.ConfigParser()\n",
    "# Read Config File\n",
    "config.read('dl.cfg')\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['AWS']['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "****A SparkSession can be used create DataFrame, register DataFrame as tables, execute SQL over \n",
    "tables, cache tables, and read parquet files. To create a SparkSession, use the following builder \n",
    "pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Initial Spark Session\n",
    "spark = SparkSession.builder.\\\n",
    "    config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "    enableHiveSupport().getOrCreate()\n",
    "fname = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "i94_df =spark.read.format('com.github.saurfang.sas.spark').load(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://4d357528f309:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fd222f7fcf8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "<h3><br>Step 2: Explore and Assess the Data </br></h3>\n",
    "<h4><br>Explore the Data</br></h4>\n",
    "Data Explorations performed using the .printSchema() method to print the inferred schema associated with the data. \n",
    "Notice that we have 28 columns (which is expected based on our format information) and column names are well laid out, datatypes are present but something can be set right based on the nature of the data, and each field is nullable. \n",
    "Note: .printSchema() is also a Spark action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n",
      "StructField(cicid,DoubleType,true)\n",
      "StructField(i94yr,DoubleType,true)\n",
      "StructField(i94mon,DoubleType,true)\n",
      "StructField(i94cit,DoubleType,true)\n",
      "StructField(i94res,DoubleType,true)\n",
      "StructField(i94port,StringType,true)\n",
      "StructField(arrdate,DoubleType,true)\n",
      "StructField(i94mode,DoubleType,true)\n",
      "StructField(i94addr,StringType,true)\n",
      "StructField(depdate,DoubleType,true)\n",
      "StructField(i94bir,DoubleType,true)\n",
      "StructField(i94visa,DoubleType,true)\n",
      "StructField(count,DoubleType,true)\n",
      "StructField(dtadfile,StringType,true)\n",
      "StructField(visapost,StringType,true)\n",
      "StructField(occup,StringType,true)\n",
      "StructField(entdepa,StringType,true)\n",
      "StructField(entdepd,StringType,true)\n",
      "StructField(entdepu,StringType,true)\n",
      "StructField(matflag,StringType,true)\n",
      "StructField(biryear,DoubleType,true)\n",
      "StructField(dtaddto,StringType,true)\n",
      "StructField(gender,StringType,true)\n",
      "StructField(insnum,StringType,true)\n",
      "StructField(airline,StringType,true)\n",
      "StructField(admnum,DoubleType,true)\n",
      "StructField(fltno,StringType,true)\n",
      "StructField(visatype,StringType,true)\n"
     ]
    }
   ],
   "source": [
    "i94_df.printSchema()\n",
    "tuple_df =i94_df.schema\n",
    "\n",
    "for d in tuple_df:\n",
    "    print(d)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"spark.jars.packages\" \"saurfang:spark-sas7bdat:2.0.0-s_2.11\"\n",
      "../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat\n",
      "Matching 1 files found in ../../data/18-83510-I94-Data-2016/ and name of the file is ../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat and all other file ['/data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat']\n",
      "\"spark.jars.packages\" \"saurfang:spark-sas7bdat:2.0.0-s_2.11\"\n",
      "\"spark.jars.packages\" \"saurfang:spark-sas7bdat:2.0.0-s_2.11\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import configparser\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "class DataUtils(object):\n",
    "    \" The class consists of pre-processing methods\"\n",
    "    \n",
    "    def read_config(self,file_name):\n",
    "        config = configparser.ConfigParser()\n",
    "        conf_file=config.read(file_name)\n",
    "        get_sections =[]\n",
    "        get_values=[]\n",
    "        for section_name in config.sections():\n",
    "                #print(f\"Section Name is {section_name}\")\n",
    "                get_sections.append(section_name)\n",
    "                #print(get_sections)\n",
    "                #print('Options:', config.options(section_name))\n",
    "                for key, value in config.items(section_name):\n",
    "                    get_values.append(value)\n",
    "                #print(get_values)\n",
    "                collect_pkg_name=get_values[0]\n",
    "                collect_lib_name=get_values[1]\n",
    "                print(collect_pkg_name,collect_lib_name)\n",
    "                return collect_pkg_name  ,collect_lib_name    \n",
    "    '''\n",
    "    def create_spark_session():\n",
    "        \"Function to create spark session\"\n",
    "        collect_pkg_name, collect_lib_name = self.read_config(\"config.ini\")\n",
    "        \n",
    "        \n",
    "        print(f\"Spark Package Name is :{pkg_name} and Library name is {lib_name}\")\n",
    "        spark = SparkSession \\\n",
    "                .builder \\\n",
    "                .config(collect_pkg_name +\",\"+ collect_lib_name) \\\n",
    "                .enableHiveSupport() \\\n",
    "                .getOrCreate()\n",
    "        spark\n",
    "        return spark, pkg_name, lib_name\n",
    "    '''\n",
    "    \n",
    "    def create_spark_session():\n",
    "        spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\") \\\n",
    "        .enableHiveSupport() \\\n",
    "        .getOrCreate()\n",
    "        return spark    \n",
    "\n",
    "    def read_immigration_file_from_path(self,filepath):\n",
    "        \"\"\" The Function to read the files from path\"\"\"\n",
    "        all_files = []\n",
    "        for root, dirs, files in os.walk(filepath):\n",
    "            files = glob.glob(os.path.join(root,'i94_apr16_sub.sas7bdat'))\n",
    "            \n",
    "            files_non_apr = glob.glob('./data/18-83510-I94-Data-2016/' + '*.sas7bdat')\n",
    "            \n",
    "            all_files = [file for file in files_non_apr if (\"apr16\" not in file)]\n",
    "            print(files[0])\n",
    "            file_name=files[0]\n",
    "            for f in files :\n",
    "                all_files.append(os.path.abspath(f))\n",
    "\n",
    "    # Get total number of files found \n",
    "        num_files = len(all_files)\n",
    "        print('Matching {} files found in {} and name of the file is {} and all other file {}'.format(num_files, filepath, file_name, all_files))\n",
    "        return filepath,file_name, all_files\n",
    "    \n",
    "    def load_i94_data(file_name):\n",
    "        \"\"\"\n",
    "        Ingests i94 data for the year 2016 from 12, monthly SAS files\n",
    "        \"\"\"\n",
    "        file_name =read_immigration_file_from_path(self,filepath)\n",
    "        spark = create_spark_session()\n",
    "        spark\n",
    "        i94_df =spark.read.format('com.github.saurfang.sas.spark').load(filepath)\n",
    "        print( i94_df.printSchema())\n",
    "                  \n",
    "def main(): \n",
    "\n",
    "    utils = DataUtils()\n",
    "    utils.read_config('config.ini')\n",
    "    \n",
    "    \n",
    "    utils.read_immigration_file_from_path('../../data/18-83510-I94-Data-2016/')\n",
    "    #print(spark_sess)\n",
    "    collect_pkg_name,collect_lib_name=utils.read_config('config.ini')\n",
    "    print(collect_pkg_name,collect_lib_name)\n",
    "    utils.create_spark_session\n",
    "    utils.load_i94_data\n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "    main()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "<h4>Identify data quality issues, like missing values, duplicate data, etc.</h4>\n",
    "\n",
    "We have created the dataframe for the initial analysis. i94_df dataframe has .show()method with \n",
    "the truncate option to False so we can see all the DataFrame columns and content. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|cicid|i94yr |i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear|dtaddto |gender|insnum|airline|admnum        |fltno|visatype|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|6.0  |2016.0|4.0   |692.0 |692.0 |XXX    |20573.0|null   |null   |null   |37.0  |2.0    |1.0  |null    |null    |null |T      |null   |U      |null   |1979.0 |10282016|null  |null  |null   |1.897628485E9 |null |B2      |\n",
      "|7.0  |2016.0|4.0   |254.0 |276.0 |ATL    |20551.0|1.0    |AL     |null   |25.0  |3.0    |1.0  |20130811|SEO     |null |G      |null   |Y      |null   |1991.0 |D/S     |M     |null  |null   |3.73679633E9  |00296|F1      |\n",
      "|15.0 |2016.0|4.0   |101.0 |101.0 |WAS    |20545.0|1.0    |MI     |20691.0|55.0  |2.0    |1.0  |20160401|null    |null |T      |O      |null   |M      |1961.0 |09302016|M     |null  |OS     |6.66643185E8  |93   |B2      |\n",
      "|16.0 |2016.0|4.0   |101.0 |101.0 |NYC    |20545.0|1.0    |MA     |20567.0|28.0  |2.0    |1.0  |20160401|null    |null |O      |O      |null   |M      |1988.0 |09302016|null  |null  |AA     |9.246846133E10|00199|B2      |\n",
      "|17.0 |2016.0|4.0   |101.0 |101.0 |NYC    |20545.0|1.0    |MA     |20567.0|4.0   |2.0    |1.0  |20160401|null    |null |O      |O      |null   |M      |2012.0 |09302016|null  |null  |AA     |9.246846313E10|00199|B2      |\n",
      "|18.0 |2016.0|4.0   |101.0 |101.0 |NYC    |20545.0|1.0    |MI     |20555.0|57.0  |1.0    |1.0  |20160401|null    |null |O      |O      |null   |M      |1959.0 |09302016|null  |null  |AZ     |9.247103803E10|00602|B1      |\n",
      "|19.0 |2016.0|4.0   |101.0 |101.0 |NYC    |20545.0|1.0    |NJ     |20558.0|63.0  |2.0    |1.0  |20160401|null    |null |O      |K      |null   |M      |1953.0 |09302016|null  |null  |AZ     |9.247139923E10|00602|B2      |\n",
      "|20.0 |2016.0|4.0   |101.0 |101.0 |NYC    |20545.0|1.0    |NJ     |20558.0|57.0  |2.0    |1.0  |20160401|null    |null |O      |K      |null   |M      |1959.0 |09302016|null  |null  |AZ     |9.247161383E10|00602|B2      |\n",
      "|21.0 |2016.0|4.0   |101.0 |101.0 |NYC    |20545.0|1.0    |NY     |20553.0|46.0  |2.0    |1.0  |20160401|null    |null |O      |O      |null   |M      |1970.0 |09302016|null  |null  |AZ     |9.247079603E10|00602|B2      |\n",
      "|22.0 |2016.0|4.0   |101.0 |101.0 |NYC    |20545.0|1.0    |NY     |20562.0|48.0  |1.0    |1.0  |20160401|null    |null |O      |O      |null   |M      |1968.0 |09302016|null  |null  |AZ     |9.247848973E10|00608|B1      |\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "***Let us count the columns in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of columns in the data file are 28 and number of rows 3096313 \n",
      "Count of distinct number of rows 3096313 \n"
     ]
    }
   ],
   "source": [
    "columns_in_file=len(i94_df.columns)\n",
    "rows_in_file=i94_df.count()\n",
    "distinct_rows_data=i94_df.distinct().count()\n",
    "print(f\"The total number of columns in the data file are {columns_in_file} and number of rows {rows_in_file} \")\n",
    "print(f\"Count of distinct number of rows {distinct_rows_data} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [cicid, count]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94_df.select([\"cicid\",\"count\"]).filter(i94_df[\"count\"] == 0).limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|i94port|count|\n",
      "+-------+-----+\n",
      "|    FMY|17514|\n",
      "|    BGM|  128|\n",
      "|    HEL|    2|\n",
      "|    DNS|   35|\n",
      "|    MOR|   14|\n",
      "|    FOK|   14|\n",
      "|    HVR|   45|\n",
      "|    SNA| 7066|\n",
      "|    PTK|   12|\n",
      "|    SPM|16973|\n",
      "|    CLG| 3191|\n",
      "|    OPF|  909|\n",
      "|    DLB|   12|\n",
      "|    ABS|    4|\n",
      "|    NAS|13032|\n",
      "|    MYR|    5|\n",
      "|    PVD|  352|\n",
      "|    OAK| 3501|\n",
      "|    FAR|    5|\n",
      "|    OTT|  663|\n",
      "+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_df.groupBy(\"i94port\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "<h3> Cleaning data </h3>\n",
    "<h6> =======================================================================================</h6>\n",
    "<h4> <br>In data cleaning process We are converting requiredcolumn into integer from double</br>\n",
    " <br>Renaming few columns to make it more meaningful.</br> \n",
    "  <br>Dropping the columns from the dataFrame </br></h4>\n",
    "<h4>Below are different transformation I have added</h4>\n",
    "<h4><br> 1.cicid cast converted to integer</br>\n",
    "<br>2.i94yr,i94mon, has been changed to year, month respectively with cast converted to integer</br>\n",
    "<br>3.We dropped the column after renaming them and used the renamed one.</br>\n",
    "<br>4.One of the transformation which I have used is usage of CASE expression and WHEN in the pyspark while data cleaning process</br>\n",
    "<br>5.As we see the flight number is inconsistent in some places, the total length is varchar(5) and in some places the string just have two digits flight number.  In order keep the consistency in the values we are padding the 0 on th eleft of each flight number making it more consistent</br>\n",
    "</h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr \n",
    "from pyspark.sql.functions import to_date\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import *\n",
    "i94_df_withColum_transformation = i94_df \\\n",
    ".withColumn(\"document_number\", col(\"cicid\").cast(\"integer\")) \\\n",
    ".withColumn(\"year\", col(\"i94yr\").cast(\"integer\")) \\\n",
    ".drop(\"i94yr\") \\\n",
    ".withColumn(\"month\", col(\"i94mon\").cast(\"integer\")) \\\n",
    ".drop(\"i94mon\") \\\n",
    ".withColumn(\"bornCountry\", col(\"i94cit\").cast(\"integer\")) \\\n",
    ".drop(\"i94cit\") \\\n",
    ".withColumn(\"residentCountry\", col(\"i94res\").cast(\"integer\")) \\\n",
    ".drop(\"i94res\") \\\n",
    ".withColumnRenamed(\"i94port\", \"arrivalPort\") \\\n",
    ".withColumn(\"mode\",col(\"i94mode\")) \\\n",
    ".withColumn(\"modeofTransportation\", col(\"i94mode\").cast(\"integer\")) \\\n",
    ".withColumn(\"modeofTransportation\",\\\n",
    "            expr(\"CASE WHEN i94mode == 1.0 THEN  'Air' WHEN i94mode == 2.0 THEN  'Sea' WHEN i94mode == 3.0 THEN  'Land' WHEN i94mode == 9.0 THEN  'Not Reported' ELSE 'other' END AS mode_of_transportation_desc\"))\\\n",
    ".drop(\"i94mode\") \\\n",
    ".withColumnRenamed(\"i94addr\", \"arrivalAddress\") \\\n",
    ".withColumn(\"age\", col(\"i94bir\").cast(\"integer\")) \\\n",
    ".drop(\"i94bir\") \\\n",
    ".withColumn(\"visa\", col(\"i94visa\").cast(\"integer\")) \\\n",
    ".withColumn('i94visa_desc',\\\n",
    "            F.when(col(\"i94visa\") == 1, 'Business')\\\n",
    "             .when(col(\"i94visa\") == 2, 'Pleasure')\\\n",
    "             .when(col(\"i94visa\") == 3, 'Student')\\\n",
    "             .otherwise('Other'))\\\n",
    ".drop(\"i94visa\") \\\n",
    ".withColumnRenamed(\"entdepa\", \"arrivalFlag\") \\\n",
    ".withColumnRenamed(\"entdepd\", \"departureFlag\") \\\n",
    ".withColumnRenamed(\"entdepu\", \"updateFlag\") \\\n",
    ".withColumnRenamed(\"matflag\", \"matchFlag\") \\\n",
    ".withColumn(\"birthYear\", col(\"biryear\").cast(\"integer\")) \\\n",
    ".drop(\"biryear\") \\\n",
    ".withColumnRenamed(\"fltno\", \"flightNumber\") \\\n",
    ".withColumn(\"flightNumber\" ,\\\n",
    "           expr(\"CASE WHEN length(flightNumber) < 5 THEN lpad(flightNumber,5,'0') ELSE flightNumber END AS flightNumber \"))\\\n",
    ".withColumnRenamed(\"visaType\", \"visaType\") \\\n",
    ".withColumn(\"sasDate\", to_date(lit(\"01/01/1960\"), \"MM/dd/yyyy\")) \\\n",
    ".withColumn(\"arrivalDate\", expr(\"date_add(sasDate, arrdate)\")) \\\n",
    ".withColumn(\"departureDate\", expr(\"date_add(sasDate, depdate)\")) \\\n",
    ".withColumn(\"totalDaysStay\", (datediff(to_date(\"departureDate\"),to_date(\"arrivalDate\")) ))\\\n",
    ".drop( \"sasDate\",\"arrdate\", \"depdate\", \"count\", \"admnum\", \"dtadfile\", \"visapost\", \"occup\", \"dtaddto\", \"insnum\")\n",
    "i94_df_withColum_transformation.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(cicid=7.0, arrivalPort='ATL', arrivalAddress='AL', arrivalFlag='G', departureFlag=None, updateFlag='Y', matchFlag=None, gender='M', airline=None, flightNumber='00296', visaType='F1', document_number=7, year=2016, month=4, bornCountry=254, residentCountry=276, modeofTransportation='Air', age=25, visa=3, i94visa_desc='Student', birthYear=1991, arrivalDate=datetime.date(2016, 4, 7), departureDate=None, totalDaysStay=nan), Row(cicid=15.0, arrivalPort='WAS', arrivalAddress='MI', arrivalFlag='T', departureFlag='O', updateFlag=None, matchFlag='M', gender='M', airline='OS', flightNumber='00093', visaType='B2', document_number=15, year=2016, month=4, bornCountry=101, residentCountry=101, modeofTransportation='Air', age=55, visa=2, i94visa_desc='Pleasure', birthYear=1961, arrivalDate=datetime.date(2016, 4, 1), departureDate=datetime.date(2016, 8, 25), totalDaysStay=146.0)]\n",
      "7.0,ATL,F1,3,G\n",
      "15.0,WAS,B2,2,T\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "import pyspark.sql as sql\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.functions import datediff, to_date, lit\n",
    "\n",
    "i94_new_dataframe=spark.createDataFrame(i94_df_withColum_transformation.filter(~col('arrivalPort').isin(['XXX'])).limit(2).toPandas()).collect()\n",
    "#i94_new_dataframe_filter = i94_new_dataframe.filter(~col('arrivalPort').isin(['XXX'])).show()\n",
    "print(i94_new_dataframe)\n",
    "# We will be iterating thru the row object \n",
    "for row in i94_new_dataframe:\n",
    "    print(str(row['cicid']) + \",\" + row['arrivalPort'] + \",\" + str(row['visaType']) +\",\" + str(row['visa']) +\",\" + str(row[\"arrivalFlag\"]))\n",
    "# Note : Loading the whole dataFrame might cause the memory error based on the size of the \n",
    "# OS configuration hence we are using limit(5) while creating the dataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Data Preparation step 1 : Check Duplicates row duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+--------------+-----------+-------------+----------+---------+------+-------+------------+--------+---------------+----+-----+-----------+---------------+--------------------+---+----+------------+---------+-----------+-------------+-------------+-----+\n",
      "|cicid|arrivalPort|arrivalAddress|arrivalFlag|departureFlag|updateFlag|matchFlag|gender|airline|flightNumber|visaType|document_number|year|month|bornCountry|residentCountry|modeofTransportation|age|visa|i94visa_desc|birthYear|arrivalDate|departureDate|totalDaysStay|count|\n",
      "+-----+-----------+--------------+-----------+-------------+----------+---------+------+-------+------------+--------+---------------+----+-----+-----------+---------------+--------------------+---+----+------------+---------+-----------+-------------+-------------+-----+\n",
      "+-----+-----------+--------------+-----------+-------------+----------+---------+------+-------+------------+--------+---------------+----+-----+-----------+---------------+--------------------+---+----+------------+---------+-----------+-------------+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_duplicates_at_row_df=i94_df_withColum_transformation.groupby(i94_df_withColum_transformation.columns).count().filter('count >1').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Data Preparation step 2 : Check Duplicates  duplicate by not including cicid column.\n",
    "#### In below we first group by columns excluding the more unique column which in our case is cicid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+-----------+-------------+----------+---------+------+-------+------------+--------+---------------+----+-----+-----------+---------------+--------------------+---+----+------------+---------+-----------+-------------+-------------+-----+\n",
      "|arrivalPort|arrivalAddress|arrivalFlag|departureFlag|updateFlag|matchFlag|gender|airline|flightNumber|visaType|document_number|year|month|bornCountry|residentCountry|modeofTransportation|age|visa|i94visa_desc|birthYear|arrivalDate|departureDate|totalDaysStay|count|\n",
      "+-----------+--------------+-----------+-------------+----------+---------+------+-------+------------+--------+---------------+----+-----+-----------+---------------+--------------------+---+----+------------+---------+-----------+-------------+-------------+-----+\n",
      "+-----------+--------------+-----------+-------------+----------+---------+------+-------+------------+--------+---------------+----+-----+-----------+---------------+--------------------+---+----+------------+---------+-----------+-------------+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_dups_without_unique_col=i94_df_withColum_transformation.groupby([col for col in i94_df_withColum_transformation.columns if col != 'cicid' ]).count().filter('count >1').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Data Preparation Step 3 : Check the distincts \n",
    "#### It looks like we do not have any such a observation for our cicid column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+\n",
      "|CounofCicid|CountOfDistinctCicid|\n",
      "+-----------+--------------------+\n",
      "|    3096313|             3096313|\n",
      "+-----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_df_withColum_transformation.agg(f.count('cicid').alias('CounofCicid'), f.countDistinct('cicid').alias('CountOfDistinctCicid')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Data Prepartion Step 4: Missing Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "###### Missing observations per row : To calculate how much amount of data is missing from a ROW, it is easier to work with RDDs as we can loop through each RDD's record and count how many values are missing\n",
    "        First access .rdd within our data frame i94_new_dataframe\n",
    "        Using .map transformation to the row object of RDDs into Dictionary \n",
    "        Since we are working with RDDs, we want to retain all the other columns. Thus,\n",
    "        we first convert the row (which is a Row(...) object) into a dictionary using the .asDict()         method, so then we can later unpack it using **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+--------------+-----------+-------------+----------+---------+------+-------+------------+--------+---------------+----+-----+-----------+---------------+--------------------+---+----+------------+---------+-----------+-------------+-------------+----------+\n",
      "|cicid|arrivalPort|arrivalAddress|arrivalFlag|departureFlag|updateFlag|matchFlag|gender|airline|flightNumber|visaType|document_number|year|month|bornCountry|residentCountry|modeofTransportation|age|visa|i94visa_desc|birthYear|arrivalDate|departureDate|totalDaysStay|total_stay|\n",
      "+-----+-----------+--------------+-----------+-------------+----------+---------+------+-------+------------+--------+---------------+----+-----+-----------+---------------+--------------------+---+----+------------+---------+-----------+-------------+-------------+----------+\n",
      "|  7.0|        ATL|            AL|          G|         null|         Y|     null|     M|   null|       00296|      F1|              7|2016|    4|        254|            276|                 Air| 25|   3|     Student|     1991| 2016-04-07|         null|          NaN|       NaN|\n",
      "| 15.0|        WAS|            MI|          T|            O|      null|        M|     M|     OS|       00093|      B2|             15|2016|    4|        101|            101|                 Air| 55|   2|    Pleasure|     1961| 2016-04-01|   2016-08-25|        146.0|     146.0|\n",
      "+-----+-----------+--------------+-----------+-------------+----------+---------+------+-------+------------+--------+---------------+----+-----+-----------+---------------+--------------------+---+----+------------+---------+-----------+-------------+-------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rdd = spark.sparkContext.parallelize(i94_new_dataframe)\n",
    "rdd.take(1)\n",
    "rdd.map(lambda row: sql.Row(\n",
    "        **row.asDict()\n",
    "        , total_stay=row.totalDaysStay\n",
    "        ) ).toDF().select(i94_df_withColum_transformation.columns + [ 'total_stay']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid_missing</th>\n",
       "      <th>arrivalPort_missing</th>\n",
       "      <th>arrivalAddress_missing</th>\n",
       "      <th>arrivalFlag_missing</th>\n",
       "      <th>departureFlag_missing</th>\n",
       "      <th>updateFlag_missing</th>\n",
       "      <th>matchFlag_missing</th>\n",
       "      <th>gender_missing</th>\n",
       "      <th>airline_missing</th>\n",
       "      <th>flightNumber_missing</th>\n",
       "      <th>...</th>\n",
       "      <th>bornCountry_missing</th>\n",
       "      <th>residentCountry_missing</th>\n",
       "      <th>modeofTransportation_missing</th>\n",
       "      <th>age_missing</th>\n",
       "      <th>visa_missing</th>\n",
       "      <th>i94visa_desc_missing</th>\n",
       "      <th>birthYear_missing</th>\n",
       "      <th>arrivalDate_missing</th>\n",
       "      <th>departureDate_missing</th>\n",
       "      <th>totalDaysStay_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049282</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.044708</td>\n",
       "      <td>0.999873</td>\n",
       "      <td>0.044708</td>\n",
       "      <td>0.133794</td>\n",
       "      <td>0.027009</td>\n",
       "      <td>0.006314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046009</td>\n",
       "      <td>0.046009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid_missing  arrivalPort_missing  arrivalAddress_missing  \\\n",
       "0            0.0                  0.0                0.049282   \n",
       "\n",
       "   arrivalFlag_missing  departureFlag_missing  updateFlag_missing  \\\n",
       "0             0.000077               0.044708            0.999873   \n",
       "\n",
       "   matchFlag_missing  gender_missing  airline_missing  flightNumber_missing  \\\n",
       "0           0.044708        0.133794         0.027009              0.006314   \n",
       "\n",
       "           ...            bornCountry_missing  residentCountry_missing  \\\n",
       "0          ...                            0.0                      0.0   \n",
       "\n",
       "   modeofTransportation_missing  age_missing  visa_missing  \\\n",
       "0                           0.0     0.000259           0.0   \n",
       "\n",
       "   i94visa_desc_missing  birthYear_missing  arrivalDate_missing  \\\n",
       "0                   0.0           0.000259                  0.0   \n",
       "\n",
       "   departureDate_missing  totalDaysStay_missing  \n",
       "0               0.046009               0.046009  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing values % from each columns\n",
    "import pyspark.sql.functions as fn\n",
    "i94_df_withColum_transformation.agg(*[\n",
    "    (1 - (fn.count(c) / fn.count('*'))).alias(c + '_missing')\n",
    "    for c in i94_df_withColum_transformation.columns\n",
    "]).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Immigration data schema:\n",
      "root\n",
      " |-- cicid: integer (nullable = true)\n",
      " |-- arrivalPort: string (nullable = true)\n",
      " |-- arrivalAddress: string (nullable = true)\n",
      " |-- arrivalFlag: string (nullable = true)\n",
      " |-- departureFlag: string (nullable = true)\n",
      " |-- updateFlag: string (nullable = true)\n",
      " |-- matchFlag: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- flightNumber: string (nullable = true)\n",
      " |-- visaType: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- bornCountry: integer (nullable = true)\n",
      " |-- residentCountry: integer (nullable = true)\n",
      " |-- modeofTransportation: string (nullable = false)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- visa: integer (nullable = true)\n",
      " |-- i94visa_desc: string (nullable = false)\n",
      " |-- birthYear: integer (nullable = true)\n",
      " |-- arrivalDate: date (nullable = true)\n",
      " |-- departureDate: date (nullable = true)\n",
      " |-- totalDaysStay: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"New Immigration data schema:\")\n",
    "i94_df_withColum_transformation.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "<h4>The .toPandas() function converts a spark dataframe into a pandas Dataframe \n",
    "which is easier to show.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>arrivalPort</th>\n",
       "      <th>arrivalAddress</th>\n",
       "      <th>arrivalFlag</th>\n",
       "      <th>departureFlag</th>\n",
       "      <th>updateFlag</th>\n",
       "      <th>matchFlag</th>\n",
       "      <th>gender</th>\n",
       "      <th>airline</th>\n",
       "      <th>flightNumber</th>\n",
       "      <th>...</th>\n",
       "      <th>bornCountry</th>\n",
       "      <th>residentCountry</th>\n",
       "      <th>modeofTransportation</th>\n",
       "      <th>age</th>\n",
       "      <th>visa</th>\n",
       "      <th>i94visa_desc</th>\n",
       "      <th>birthYear</th>\n",
       "      <th>arrivalDate</th>\n",
       "      <th>departureDate</th>\n",
       "      <th>totalDaysStay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>XXX</td>\n",
       "      <td>None</td>\n",
       "      <td>T</td>\n",
       "      <td>None</td>\n",
       "      <td>U</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>692</td>\n",
       "      <td>692</td>\n",
       "      <td>other</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>1979</td>\n",
       "      <td>2016-04-29</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>ATL</td>\n",
       "      <td>AL</td>\n",
       "      <td>G</td>\n",
       "      <td>None</td>\n",
       "      <td>Y</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>00296</td>\n",
       "      <td>...</td>\n",
       "      <td>254</td>\n",
       "      <td>276</td>\n",
       "      <td>Air</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>Student</td>\n",
       "      <td>1991</td>\n",
       "      <td>2016-04-07</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>WAS</td>\n",
       "      <td>MI</td>\n",
       "      <td>T</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>OS</td>\n",
       "      <td>00093</td>\n",
       "      <td>...</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>Air</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>1961</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-08-25</td>\n",
       "      <td>146.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>NYC</td>\n",
       "      <td>MA</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>AA</td>\n",
       "      <td>00199</td>\n",
       "      <td>...</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>Air</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>1988</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>NYC</td>\n",
       "      <td>MA</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>AA</td>\n",
       "      <td>00199</td>\n",
       "      <td>...</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>Air</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>2012</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid arrivalPort arrivalAddress arrivalFlag departureFlag updateFlag  \\\n",
       "0      6         XXX           None           T          None          U   \n",
       "1      7         ATL             AL           G          None          Y   \n",
       "2     15         WAS             MI           T             O       None   \n",
       "3     16         NYC             MA           O             O       None   \n",
       "4     17         NYC             MA           O             O       None   \n",
       "\n",
       "  matchFlag gender airline flightNumber      ...       bornCountry  \\\n",
       "0      None   None    None         None      ...               692   \n",
       "1      None      M    None        00296      ...               254   \n",
       "2         M      M      OS        00093      ...               101   \n",
       "3         M   None      AA        00199      ...               101   \n",
       "4         M   None      AA        00199      ...               101   \n",
       "\n",
       "   residentCountry  modeofTransportation  age  visa i94visa_desc  birthYear  \\\n",
       "0              692                 other   37     2     Pleasure       1979   \n",
       "1              276                   Air   25     3      Student       1991   \n",
       "2              101                   Air   55     2     Pleasure       1961   \n",
       "3              101                   Air   28     2     Pleasure       1988   \n",
       "4              101                   Air    4     2     Pleasure       2012   \n",
       "\n",
       "   arrivalDate departureDate  totalDaysStay  \n",
       "0   2016-04-29          None            NaN  \n",
       "1   2016-04-07          None            NaN  \n",
       "2   2016-04-01    2016-08-25          146.0  \n",
       "3   2016-04-01    2016-04-23           22.0  \n",
       "4   2016-04-01    2016-04-23           22.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94_df_withColum_transformation.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "<h3>Additional Check : Checking the Schema for the above file loaded into Spark </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## File Name validate_setup.py\n",
    "## Addition Verification step Custome function created to check if directory exits\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "'''\n",
    "    Function to check if the directory used\n",
    "    to write the parquet data is present if not\n",
    "    create one and add parquet file\n",
    "    \n",
    "    Parameters : \n",
    "        folder_name : Pass the value for folder_name\n",
    "        parquet_file_name : Pass the filename with .parquet extention\n",
    "        \n",
    "'''\n",
    "\n",
    "def parquet_check_n_create(folder_name, parquet_store_name):\n",
    "    try:\n",
    "        if os.path.isdir(folder_name) == False:\n",
    "            print(f\"FolderNameCheck::The {folder_name} does not exits...!! Creating {folder_name}\")\n",
    "            i94_df.write.parquet(folder_name +\"/\" + parquet_store_name)\n",
    "        else:\n",
    "            shutil.rmtree(folder_name)\n",
    "            i94_df.write.parquet(folder_name +\"/\" + parquet_store_name)\n",
    "            print(f\"FolderNameCheck:The {folder_name} does exits...!! Using existing {folder_name}\")\n",
    "    except:\n",
    "       \n",
    "        print(\"Something went wrong\")\n",
    "    else:\n",
    "        print(\"Nothing went wrong\")\n",
    "        \n",
    "#if __name__==\"__main__\":\n",
    "#    check_if_spark_dir_exists('_sas_data','i94_df.parquet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "<h3>Step 3: Define the Data Model</h3>\n",
    "*****3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "For the purpose of this project we will be using the STAR schema or model close to star schema. Using STAR schema we will be in position to normalize our data sets and also build a strong relationship by defining and implementing the relationships using primary, foreging keys etc.\n",
    "\n",
    "Below is the conceptualize data model\n",
    "\n",
    "![alt text](CapstoneDataModel.png \"Title\")\n",
    "\n",
    "*****3.2 Mapping Out Data Pipelines\n",
    "\n",
    "****Step 1 : First we will be loading our data file under ../data/ folder\n",
    "Step 2: Read the file in SparkDataFrame\n",
    "Step 3: Clean the file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Data dictionary\n",
    "<table style=\"width:50%\">\n",
    "<tr>\n",
    "<th>ColumnName</th>\n",
    "<th>Description</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "    <td>cicid </td>\n",
    "    <td>Unique record ID</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>i94yr </td>\n",
    "    <td>4 digit year</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>i94mon</td>\n",
    "    <td>Numeric month</td>\n",
    "    </tr>\n",
    "<tr>\n",
    "    <td>i94cit3</td>\n",
    "    <td>digit code for immigrant country of birth</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>i94res</td>\n",
    "    <td>3 digit code for immigrant country of residence </td> </tr>\n",
    "<tr>\n",
    "    <td>i94port</td>\n",
    "    <td>Port of admission</td>\n",
    "</tr>\n",
    "    <tr><td>arrdate</td><td> Arrival Date in the USA</td></tr>\n",
    "<tr><td>i94mode</td><td> Mode of transportation (1 = Air; 2 = Sea; 3 = Land; 9 = Not reported)</td></tr>\n",
    "<tr><td>i94addr</td><td> USA State of arrival</td></tr>\n",
    "<tr><td>depdate</td><td> Departure Date from the USA</td></tr>\n",
    "<tr><td>i94bir</td><td> Age of Respondent in Years</td></tr>\n",
    "<tr><td>i94visa</td><td> Visa codes collapsed into three categories</td></tr>\n",
    "<tr><td>count</td><td> Field used for summary statistics</td></tr>\n",
    "<tr><td>dtadfile</td><td> Character Date Field - Date added to I-94 Files</td></tr>\n",
    "<tr><td>visapost</td><td> Department of State where where Visa was issued</td></tr>\n",
    "<tr><td>occup</td><td> Occupation that will be performed in U.S</td></tr>\n",
    "<tr><td>entdepa</td><td> Arrival Flag - admitted or paroled into the U.S.</td></tr>\n",
    "<tr><td>entdepd</td><td> Departure Flag - Departed, lost I-94 or is deceased</td></tr>\n",
    "<tr><td>entdepu</td><td> Update Flag - Either apprehended, overstayed, adjusted to perm residence</td></tr>\n",
    "<tr><td>matflag</td><td> Match flag - Match of arrival and departure records</td></tr>\n",
    "<tr><td>biryear</td><td> 4 digit year of birth</td></tr>\n",
    "<tr><td>dtaddto</td><td> Character Date Field - Date to which admitted to U.S. (allowed to stay until)</td></tr>\n",
    "<tr><td>gender</td><td> Non-immigrant sex</td></tr>\n",
    "<tr><td>insnum</td><td> INS number</td></tr>\n",
    "<tr><td>airline</td><td> Airline used to arrive in U.S.</td></tr>\n",
    "<tr><td>admnum</td><td> Admission Number</td></tr>\n",
    "<tr><td>fltno</td><td> Flight number of Airline used to arrive in U.S.</td></tr>\n",
    "<tr><td>visatype</td><td> Class of admission legally admitting the non-immigrant to temporarily stay in U.S.</td></tr>\n",
    "    </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "<h4> Count Total number of rows in I_94 SAS data set <h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3096313 total lines in the file\n"
     ]
    }
   ],
   "source": [
    "Tot_number_of_rows_in_i94_df = i94_df_withColum_transformation.count()\n",
    "print(f\"There are {Tot_number_of_rows_in_i94_df} total lines in the file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3096313\n"
     ]
    }
   ],
   "source": [
    "# Check the duplicate in Unique Records\n",
    "i94_df_2 = i94_df_withColum_transformation.select(['cicid']).count()\n",
    "print(i94_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94_df_post_duplicate_removal =i94_df_withColum_transformation.dropDuplicates(['cicid'])\n",
    "i94_df_post_duplicate_removal.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "<H5> Data Exploration: \n",
    " Explore different modes of transportations \n",
    " Distinct Mode of transportation (1 = Air; 2 = Sea; 3 = Land; 9 = Not reported\n",
    " We see in below data there are nulls present for this field and we have added not reported in place of nulls<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|modeofTransportation|\n",
      "+--------------------+\n",
      "|        Not Reported|\n",
      "|                 Sea|\n",
      "|               other|\n",
      "|                Land|\n",
      "|                 Air|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_df_withColum_transformation.select(['modeofTransportation']).distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "### Build the data pipelines to create the data model.\n",
    "### Implementing the dimentionalize mode based on above model in step 3\n",
    "\n",
    "###### Data Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "<h2>dim_visa_category</h2>\n",
    "<h3>Table to hold the visa category information of he travelers</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+--------------------+\n",
      "|visaCategoryID|visaType|    visaCateogryDesc|\n",
      "+--------------+--------+--------------------+\n",
      "|  103079215104|      F2|    Educational Visa|\n",
      "|  352187318272|     GMB|                 UNK|\n",
      "|  369367187456|      B2|Business Sponsor ...|\n",
      "|  498216206336|      F1|    Educational Visa|\n",
      "|  601295421440|     CPL|                 UNK|\n",
      "|  704374636544|      I1|                 UNK|\n",
      "|  738734374912|      WB|                 UNK|\n",
      "|  747324309504|      M1|                 UNK|\n",
      "|  807453851648|      B1|Business Sponsor ...|\n",
      "|  884763262976|      WT|                 UNK|\n",
      "| 1151051235328|      M2|                 UNK|\n",
      "| 1314259992576|      CP|                 UNK|\n",
      "| 1331439861760|     GMT|                 UNK|\n",
      "| 1348619730944|      E1|                 UNK|\n",
      "| 1391569403904|       I|                 UNK|\n",
      "| 1554778161152|      E2|                 UNK|\n",
      "| 1709396983808|     SBP|                 UNK|\n",
      "+--------------+--------+--------------------+\n",
      "\n",
      "root\n",
      " |-- visaCategoryID: long (nullable = false)\n",
      " |-- visaType: string (nullable = true)\n",
      " |-- visaCateogryDesc: string (nullable = false)\n",
      "\n",
      "FolderNameCheck:The _sas_data_visa_cat does exits...!! Using existing _sas_data_visa_cat\n",
      "Nothing went wrong\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "dim_visa_category= i94_df_withColum_transformation.select(['visaType']).alias('visaCatType').distinct()\n",
    "\n",
    "dim_visa_category = dim_visa_category \\\n",
    "                    .withColumn('visaCategoryID', monotonically_increasing_id())\n",
    "dim_visa_category = dim_visa_category.select(['visaCategoryID','visaType'])  \n",
    "dim_visa_category = dim_visa_category.withColumn('visaCateogryDesc', \\\n",
    "                    when(col(\"visaType\").startswith(\"F\"),\"Educational Visa\") \\\n",
    "                    .when(col(\"visaType\").isin(\"B1\",\"B2\"), \"Business Sponsor visa\").otherwise(\"UNK\").cast(\"string\") ) \n",
    "                    \n",
    "\n",
    "dim_visa_category.show()\n",
    "dim_visa_category.printSchema()   \n",
    "#dim_visa_category.write.parquet(\"_sas_data_visa_cat/dim_visa_category.parquet\")\n",
    "parquet_check_n_create(\"_sas_data_visa_cat\",\"dim_visa_category.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "<h2>dim_arrival_port</h2>\n",
    "<h3> Table to store the arrival data for the travelers</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+\n",
      "|port_id|port_nm|State|\n",
      "+-------+-------+-----+\n",
      "|      0|    XXX| null|\n",
      "|      1|    ATL|   AL|\n",
      "|      2|    WAS|   MI|\n",
      "|      3|    NYC|   MA|\n",
      "|      4|    NYC|   MA|\n",
      "|      5|    NYC|   MI|\n",
      "|      6|    NYC|   NJ|\n",
      "|      7|    NYC|   NJ|\n",
      "|      8|    NYC|   NY|\n",
      "|      9|    NYC|   NY|\n",
      "|     10|    NYC|   NY|\n",
      "|     11|    TOR|   MO|\n",
      "|     12|    BOS|   MA|\n",
      "|     13|    ATL|   MA|\n",
      "|     14|    ATL|   MA|\n",
      "|     15|    ATL|   NJ|\n",
      "|     16|    ATL|   NY|\n",
      "|     17|    HOU|   TX|\n",
      "|     18|    NYC|   CT|\n",
      "|     19|    NYC|   CT|\n",
      "+-------+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- port_id: long (nullable = false)\n",
      " |-- port_nm: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      "\n",
      "FolderNameCheck:The _sas_data_arrival_port does exits...!! Using existing _sas_data_arrival_port\n",
      "Nothing went wrong\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "\n",
    "dim_arrival_port = i94_df_withColum_transformation \\\n",
    "              .withColumn('port_id', monotonically_increasing_id()) \\\n",
    "              .withColumn('port_nm', col('arrivalPort')) \\\n",
    "              .withColumn('State',col('arrivalAddress') )\n",
    "\n",
    "dim_arrival_port = dim_arrival_port.select(['port_id','port_nm','State'])  \n",
    "                    \n",
    "\n",
    "dim_arrival_port.show()\n",
    "dim_arrival_port.printSchema()   \n",
    "parquet_check_n_create(\"_sas_data_arrival_port\",\"dim_arrival_port.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### dim_mode_transportations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- mode_id: long (nullable = false)\n",
      " |-- mode: double (nullable = true)\n",
      " |-- modeOfTransportation: string (nullable = false)\n",
      "\n",
      "FolderNameCheck::The _sas_mode_of_transp does not exits...!! Creating _sas_mode_of_transp\n",
      "Nothing went wrong\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "\n",
    "dim_mode_transportation = i94_df_withColum_transformation \\\n",
    "              .withColumn('mode_id', monotonically_increasing_id()) \\\n",
    "              .withColumn('mode', col('mode')) \\\n",
    "              .withColumn('modeOfTransportations',col('modeOfTransportation') )\n",
    "\n",
    "dim_mode_transportation = dim_mode_transportation.select(['mode_id','mode','modeOfTransportation'])  \n",
    "                    \n",
    "\n",
    "dim_mode_transportation.toPandas()\n",
    "dim_mode_transportation.printSchema()   \n",
    "parquet_check_n_create(\"_sas_mode_of_transp\",\"dim_mode_transportation.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "<h3>Load/Staging : dim_visa_category</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|    cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|5748517.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     CA|20582.0|  40.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1976.0|10292016|     F|  null|     QF|9.495387003E10|00011|      B1|\n",
      "|5748518.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     NV|20591.0|  32.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1984.0|10292016|     F|  null|     VA|9.495562283E10|00007|      B1|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Drop table tempview if exist\n",
    "spark.catalog.dropTempView('dim_visa_category')\n",
    "# Load the temp view\n",
    "load_temp_data =spark.sql(\"CREATE TEMPORARY VIEW dim_visa_category USING parquet OPTIONS (path \\\"_sas_data_visa_cat/dim_visa_category.parquet\\\")\")\n",
    "# select from temp view\n",
    "spark.sql(\"SELECT * FROM dim_visa_category\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "<h3>Load/Staging : dim_arrival_port</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|    cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|5748517.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     CA|20582.0|  40.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1976.0|10292016|     F|  null|     QF|9.495387003E10|00011|      B1|\n",
      "|5748518.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     NV|20591.0|  32.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1984.0|10292016|     F|  null|     VA|9.495562283E10|00007|      B1|\n",
      "|5748519.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     WA|20582.0|  29.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1987.0|10292016|     M|  null|     DL|9.495640653E10|00040|      B1|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Drop table tempview if exist\n",
    "spark.catalog.dropTempView('dim_arrival_port')\n",
    "# Load the temp view\n",
    "load_temp_data =spark.sql(\"CREATE TEMPORARY VIEW dim_arrival_port USING parquet OPTIONS (path \\\"_sas_data_arrival_port/dim_arrival_port.parquet\\\")\")\n",
    "# select from temp view\n",
    "spark.sql(\"SELECT * FROM dim_arrival_port\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "<h3>Loading/Staging : dim_mode_transportation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|    cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|5748517.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     CA|20582.0|  40.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1976.0|10292016|     F|  null|     QF|9.495387003E10|00011|      B1|\n",
      "|5748518.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     NV|20591.0|  32.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1984.0|10292016|     F|  null|     VA|9.495562283E10|00007|      B1|\n",
      "|5748519.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     WA|20582.0|  29.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1987.0|10292016|     M|  null|     DL|9.495640653E10|00040|      B1|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Drop table tempview if exist\n",
    "spark.catalog.dropTempView('dim_mode_transportaion')\n",
    "# Load the temp view\n",
    "load_temp_data =spark.sql(\"CREATE TEMPORARY VIEW dim_mode_transportaion USING parquet OPTIONS (path \\\"_sas_mode_of_transp/dim_mode_transportation.parquet\\\")\")\n",
    "# select from temp view\n",
    "spark.sql(\"SELECT * FROM dim_mode_transportaion\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "<h3> dim_time</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FolderNameCheck:The _sas_data_time_dim does exits...!! Using existing _sas_data_time_dim\n",
      "Nothing went wrong\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-04-06</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-04-11</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-04-16</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016-04-10</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016-04-09</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016-04-07</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016-04-05</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016-04-18</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         time  day  month  year  week  weekday\n",
       "0  2016-04-01    1      4  2016    13        6\n",
       "1  2016-04-06    6      4  2016    14        4\n",
       "2  2016-04-11   11      4  2016    15        2\n",
       "3  2016-04-28   28      4  2016    17        5\n",
       "4  2016-04-16   16      4  2016    15        7\n",
       "5  2016-04-10   10      4  2016    14        1\n",
       "6  2016-04-09    9      4  2016    14        7\n",
       "7  2016-04-07    7      4  2016    14        5\n",
       "8  2016-04-05    5      4  2016    14        3\n",
       "9  2016-04-18   18      4  2016    16        2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_time = i94_df_withColum_transformation.select(['arrivalDate'])\\\n",
    "                    .withColumnRenamed('arrivalDate','time') \n",
    "\n",
    "dim_time_tbl = dim_time \\\n",
    "             .withColumn('day', F.dayofmonth('time')) \\\n",
    "             .withColumn('month', F.month('time')) \\\n",
    "             .withColumn('year', F.year('time')) \\\n",
    "             .withColumn('week', F.weekofyear('time')) \\\n",
    "             .withColumn('weekday', F.dayofweek('time'))\\\n",
    "             .dropDuplicates()\n",
    "    \n",
    "#dim_time_tbl.write.parquet(\"_sas_data_time_dim/time_dim.parquet\")\n",
    "parquet_check_n_create(\"_sas_data_time_dim\",\"time_dim.parquet\")\n",
    "dim_time_tbl.limit(10).toPandas()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- time: date (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- week: integer (nullable = true)\n",
      " |-- weekday: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim_time_tbl.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "<h4> Loading the data in temp view using the above parquet file. Here we are creating the \n",
    "time_dim table and loading it from the path parquet output path</h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|    cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|5748517.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     CA|20582.0|  40.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1976.0|10292016|     F|  null|     QF|9.495387003E10|00011|      B1|\n",
      "|5748518.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     NV|20591.0|  32.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1984.0|10292016|     F|  null|     VA|9.495562283E10|00007|      B1|\n",
      "|5748519.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     WA|20582.0|  29.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1987.0|10292016|     M|  null|     DL|9.495640653E10|00040|      B1|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Drop table tempview if exist\n",
    "spark.catalog.dropTempView('time_dim')\n",
    "# Load the temp view\n",
    "load_temp_data =spark.sql(\"CREATE TEMPORARY VIEW time_dim USING parquet OPTIONS (path \\\"_sas_data_time_dim/time_dim.parquet\\\")\")\n",
    "# select from temp view\n",
    "spark.sql(\"SELECT * FROM time_dim\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "<h4>Get the count per i94port\n",
    "Demonstrating the filtering techniques in pyspark on the data We can filter a data frame using multiple conditions using AND(&), OR(|) and NOT(~) conditions.\n",
    "For example, we may want to find out all the different infection_case in Daegu Province with more\n",
    "than 10 confirmed cases. <h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>arrivalPort</th>\n",
       "      <th>arrivalAddress</th>\n",
       "      <th>arrivalFlag</th>\n",
       "      <th>departureFlag</th>\n",
       "      <th>updateFlag</th>\n",
       "      <th>matchFlag</th>\n",
       "      <th>modeofTransportation</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>...</th>\n",
       "      <th>visaType</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>bornCountry</th>\n",
       "      <th>residentCountry</th>\n",
       "      <th>visa</th>\n",
       "      <th>i94visa_desc</th>\n",
       "      <th>birthYear</th>\n",
       "      <th>arrivalDate</th>\n",
       "      <th>departureDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>None</td>\n",
       "      <td>T</td>\n",
       "      <td>None</td>\n",
       "      <td>U</td>\n",
       "      <td>None</td>\n",
       "      <td>other</td>\n",
       "      <td>None</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>B2</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>692</td>\n",
       "      <td>692</td>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>1979</td>\n",
       "      <td>2016-04-29</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>AL</td>\n",
       "      <td>G</td>\n",
       "      <td>None</td>\n",
       "      <td>Y</td>\n",
       "      <td>None</td>\n",
       "      <td>Air</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>F1</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>254</td>\n",
       "      <td>276</td>\n",
       "      <td>3</td>\n",
       "      <td>Student</td>\n",
       "      <td>1991</td>\n",
       "      <td>2016-04-07</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>MI</td>\n",
       "      <td>T</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>Air</td>\n",
       "      <td>M</td>\n",
       "      <td>55</td>\n",
       "      <td>...</td>\n",
       "      <td>B2</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>1961</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-08-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>MA</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>Air</td>\n",
       "      <td>None</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>B2</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>1988</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>MA</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>Air</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>B2</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>2012</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>MI</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>Air</td>\n",
       "      <td>None</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>B1</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>Business</td>\n",
       "      <td>1959</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>NJ</td>\n",
       "      <td>O</td>\n",
       "      <td>K</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>Air</td>\n",
       "      <td>None</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>B2</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>1953</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>NJ</td>\n",
       "      <td>O</td>\n",
       "      <td>K</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>Air</td>\n",
       "      <td>None</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>B2</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>1959</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>NY</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>Air</td>\n",
       "      <td>None</td>\n",
       "      <td>46</td>\n",
       "      <td>...</td>\n",
       "      <td>B2</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>1970</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>NY</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>Air</td>\n",
       "      <td>None</td>\n",
       "      <td>48</td>\n",
       "      <td>...</td>\n",
       "      <td>B1</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>Business</td>\n",
       "      <td>1968</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>23.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>NY</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>Air</td>\n",
       "      <td>None</td>\n",
       "      <td>52</td>\n",
       "      <td>...</td>\n",
       "      <td>B2</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>1964</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-08-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>24.0</td>\n",
       "      <td>TOR</td>\n",
       "      <td>MO</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>Air</td>\n",
       "      <td>None</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>B2</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>1983</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    cicid arrivalPort arrivalAddress arrivalFlag departureFlag updateFlag  \\\n",
       "0     6.0         XXX           None           T          None          U   \n",
       "1     7.0         ATL             AL           G          None          Y   \n",
       "2    15.0         WAS             MI           T             O       None   \n",
       "3    16.0         NYC             MA           O             O       None   \n",
       "4    17.0         NYC             MA           O             O       None   \n",
       "5    18.0         NYC             MI           O             O       None   \n",
       "6    19.0         NYC             NJ           O             K       None   \n",
       "7    20.0         NYC             NJ           O             K       None   \n",
       "8    21.0         NYC             NY           O             O       None   \n",
       "9    22.0         NYC             NY           O             O       None   \n",
       "10   23.0         NYC             NY           O             O       None   \n",
       "11   24.0         TOR             MO           O             O       None   \n",
       "\n",
       "   matchFlag modeofTransportation gender  age      ...       visaType  year  \\\n",
       "0       None                other   None   37      ...             B2  2016   \n",
       "1       None                  Air      M   25      ...             F1  2016   \n",
       "2          M                  Air      M   55      ...             B2  2016   \n",
       "3          M                  Air   None   28      ...             B2  2016   \n",
       "4          M                  Air   None    4      ...             B2  2016   \n",
       "5          M                  Air   None   57      ...             B1  2016   \n",
       "6          M                  Air   None   63      ...             B2  2016   \n",
       "7          M                  Air   None   57      ...             B2  2016   \n",
       "8          M                  Air   None   46      ...             B2  2016   \n",
       "9          M                  Air   None   48      ...             B1  2016   \n",
       "10         M                  Air   None   52      ...             B2  2016   \n",
       "11         M                  Air   None   33      ...             B2  2016   \n",
       "\n",
       "   month  bornCountry  residentCountry  visa  i94visa_desc  birthYear  \\\n",
       "0      4          692              692     2      Pleasure       1979   \n",
       "1      4          254              276     3       Student       1991   \n",
       "2      4          101              101     2      Pleasure       1961   \n",
       "3      4          101              101     2      Pleasure       1988   \n",
       "4      4          101              101     2      Pleasure       2012   \n",
       "5      4          101              101     1      Business       1959   \n",
       "6      4          101              101     2      Pleasure       1953   \n",
       "7      4          101              101     2      Pleasure       1959   \n",
       "8      4          101              101     2      Pleasure       1970   \n",
       "9      4          101              101     1      Business       1968   \n",
       "10     4          101              101     2      Pleasure       1964   \n",
       "11     4          101              101     2      Pleasure       1983   \n",
       "\n",
       "   arrivalDate  departureDate  \n",
       "0   2016-04-29           None  \n",
       "1   2016-04-07           None  \n",
       "2   2016-04-01     2016-08-25  \n",
       "3   2016-04-01     2016-04-23  \n",
       "4   2016-04-01     2016-04-23  \n",
       "5   2016-04-01     2016-04-11  \n",
       "6   2016-04-01     2016-04-14  \n",
       "7   2016-04-01     2016-04-14  \n",
       "8   2016-04-01     2016-04-09  \n",
       "9   2016-04-01     2016-04-18  \n",
       "10  2016-04-01     2016-08-05  \n",
       "11  2016-04-01     2016-04-10  \n",
       "\n",
       "[12 rows x 22 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "    Creating a new data frame by selecting few \n",
    "    columns of interest for our further analysis\n",
    "'''\n",
    "i94_df_select = i94_df_withColum_transformation.select('cicid','arrivalPort','arrivalAddress','arrivalFlag','departureFlag','updateFlag','matchFlag','modeofTransportation','gender','age','airline','flightNumber', \\\n",
    "                                                      'visaType','year','month','bornCountry','residentCountry','visa','i94visa_desc','birthYear','arrivalDate','departureDate')\n",
    "i94_df_select.limit(12).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Dropping the Nulls from our data set to clean the data and taking the counts POST null removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>arrivalPort</th>\n",
       "      <th>arrivalAddress</th>\n",
       "      <th>arrivalFlag</th>\n",
       "      <th>departureFlag</th>\n",
       "      <th>updateFlag</th>\n",
       "      <th>matchFlag</th>\n",
       "      <th>modeofTransportation</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>...</th>\n",
       "      <th>visaType</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>bornCountry</th>\n",
       "      <th>residentCountry</th>\n",
       "      <th>visa</th>\n",
       "      <th>i94visa_desc</th>\n",
       "      <th>birthYear</th>\n",
       "      <th>arrivalDate</th>\n",
       "      <th>departureDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61647.0</td>\n",
       "      <td>MAA</td>\n",
       "      <td>AZ</td>\n",
       "      <td>T</td>\n",
       "      <td>O</td>\n",
       "      <td>U</td>\n",
       "      <td>M</td>\n",
       "      <td>Air</td>\n",
       "      <td>F</td>\n",
       "      <td>47</td>\n",
       "      <td>...</td>\n",
       "      <td>B2</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>213</td>\n",
       "      <td>213</td>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>1969</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-05-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78629.0</td>\n",
       "      <td>HOU</td>\n",
       "      <td>NY</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>U</td>\n",
       "      <td>M</td>\n",
       "      <td>Air</td>\n",
       "      <td>M</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>B2</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>258</td>\n",
       "      <td>261</td>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>1980</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85237.0</td>\n",
       "      <td>PSP</td>\n",
       "      <td>TX</td>\n",
       "      <td>G</td>\n",
       "      <td>N</td>\n",
       "      <td>U</td>\n",
       "      <td>M</td>\n",
       "      <td>Air</td>\n",
       "      <td>M</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>B2</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>343</td>\n",
       "      <td>343</td>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>1973</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85299.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>TX</td>\n",
       "      <td>G</td>\n",
       "      <td>N</td>\n",
       "      <td>U</td>\n",
       "      <td>M</td>\n",
       "      <td>Air</td>\n",
       "      <td>M</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>B2</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>343</td>\n",
       "      <td>343</td>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>1973</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90022.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>CA</td>\n",
       "      <td>G</td>\n",
       "      <td>N</td>\n",
       "      <td>U</td>\n",
       "      <td>M</td>\n",
       "      <td>Air</td>\n",
       "      <td>F</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>WT</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>438</td>\n",
       "      <td>438</td>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>1987</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>207310.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>MA</td>\n",
       "      <td>G</td>\n",
       "      <td>N</td>\n",
       "      <td>U</td>\n",
       "      <td>M</td>\n",
       "      <td>Air</td>\n",
       "      <td>M</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>B2</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>689</td>\n",
       "      <td>689</td>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>1994</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>210130.0</td>\n",
       "      <td>MIA</td>\n",
       "      <td>FL</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>U</td>\n",
       "      <td>M</td>\n",
       "      <td>Air</td>\n",
       "      <td>M</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>F2</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>689</td>\n",
       "      <td>689</td>\n",
       "      <td>3</td>\n",
       "      <td>Student</td>\n",
       "      <td>1997</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-05-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>213451.0</td>\n",
       "      <td>MIA</td>\n",
       "      <td>GA</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>U</td>\n",
       "      <td>M</td>\n",
       "      <td>Air</td>\n",
       "      <td>M</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>B1</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>691</td>\n",
       "      <td>691</td>\n",
       "      <td>1</td>\n",
       "      <td>Business</td>\n",
       "      <td>1974</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-06-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>217696.0</td>\n",
       "      <td>NCA</td>\n",
       "      <td>FL</td>\n",
       "      <td>G</td>\n",
       "      <td>N</td>\n",
       "      <td>U</td>\n",
       "      <td>M</td>\n",
       "      <td>Air</td>\n",
       "      <td>M</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>B2</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>696</td>\n",
       "      <td>696</td>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>1965</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>217697.0</td>\n",
       "      <td>NCA</td>\n",
       "      <td>FL</td>\n",
       "      <td>G</td>\n",
       "      <td>N</td>\n",
       "      <td>U</td>\n",
       "      <td>M</td>\n",
       "      <td>Air</td>\n",
       "      <td>M</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>B2</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>696</td>\n",
       "      <td>696</td>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>1997</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cicid arrivalPort arrivalAddress arrivalFlag departureFlag updateFlag  \\\n",
       "0   61647.0         MAA             AZ           T             O          U   \n",
       "1   78629.0         HOU             NY           G             O          U   \n",
       "2   85237.0         PSP             TX           G             N          U   \n",
       "3   85299.0         LOS             TX           G             N          U   \n",
       "4   90022.0         ATL             CA           G             N          U   \n",
       "5  207310.0         ATL             MA           G             N          U   \n",
       "6  210130.0         MIA             FL           G             O          U   \n",
       "7  213451.0         MIA             GA           G             O          U   \n",
       "8  217696.0         NCA             FL           G             N          U   \n",
       "9  217697.0         NCA             FL           G             N          U   \n",
       "\n",
       "  matchFlag modeofTransportation gender  age      ...       visaType  year  \\\n",
       "0         M                  Air      F   47      ...             B2  2016   \n",
       "1         M                  Air      M   36      ...             B2  2016   \n",
       "2         M                  Air      M   43      ...             B2  2016   \n",
       "3         M                  Air      M   43      ...             B2  2016   \n",
       "4         M                  Air      F   29      ...             WT  2016   \n",
       "5         M                  Air      M   22      ...             B2  2016   \n",
       "6         M                  Air      M   19      ...             F2  2016   \n",
       "7         M                  Air      M   42      ...             B1  2016   \n",
       "8         M                  Air      M   51      ...             B2  2016   \n",
       "9         M                  Air      M   19      ...             B2  2016   \n",
       "\n",
       "  month  bornCountry  residentCountry  visa  i94visa_desc  birthYear  \\\n",
       "0     4          213              213     2      Pleasure       1969   \n",
       "1     4          258              261     2      Pleasure       1980   \n",
       "2     4          343              343     2      Pleasure       1973   \n",
       "3     4          343              343     2      Pleasure       1973   \n",
       "4     4          438              438     2      Pleasure       1987   \n",
       "5     4          689              689     2      Pleasure       1994   \n",
       "6     4          689              689     3       Student       1997   \n",
       "7     4          691              691     1      Business       1974   \n",
       "8     4          696              696     2      Pleasure       1965   \n",
       "9     4          696              696     2      Pleasure       1997   \n",
       "\n",
       "  arrivalDate  departureDate  \n",
       "0  2016-04-01     2016-05-28  \n",
       "1  2016-04-01     2016-04-30  \n",
       "2  2016-04-01     2016-04-21  \n",
       "3  2016-04-01     2016-04-07  \n",
       "4  2016-04-01     2016-06-30  \n",
       "5  2016-04-01     2016-04-07  \n",
       "6  2016-04-01     2016-05-19  \n",
       "7  2016-04-01     2016-06-15  \n",
       "8  2016-04-01     2016-04-15  \n",
       "9  2016-04-01     2016-04-15  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94_df_drop_nulls=i94_df_select.na.drop()\n",
    "i94_df_drop_nulls.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 218 total lines in the file post dropping nulls\n"
     ]
    }
   ],
   "source": [
    "Tot_number_of_rows_in_i94_df_POST_null_removal = i94_df_drop_nulls.count()\n",
    "print(f\"There are {Tot_number_of_rows_in_i94_df_POST_null_removal} total lines in the file post dropping nulls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+--------------+-----------+-------------+----------+---------+--------------------+------+---+-------+------------+--------+----+-----+-----------+---------------+----+------------+---------+-----------+-------------+\n",
      "|cicid|arrivalPort|arrivalAddress|arrivalFlag|departureFlag|updateFlag|matchFlag|modeofTransportation|gender|age|airline|flightNumber|visaType|year|month|bornCountry|residentCountry|visa|i94visa_desc|birthYear|arrivalDate|departureDate|\n",
      "+-----+-----------+--------------+-----------+-------------+----------+---------+--------------------+------+---+-------+------------+--------+----+-----+-----------+---------------+----+------------+---------+-----------+-------------+\n",
      "|  6.0|        XXX|          null|          T|         null|         U|     null|               other|  null| 37|   null|        null|      B2|2016|    4|        692|            692|   2|    Pleasure|     1979| 2016-04-29|         null|\n",
      "|  7.0|        ATL|            AL|          G|         null|         Y|     null|                 Air|     M| 25|   null|       00296|      F1|2016|    4|        254|            276|   3|     Student|     1991| 2016-04-07|         null|\n",
      "| 15.0|        WAS|            MI|          T|            O|      null|        M|                 Air|     M| 55|     OS|       00093|      B2|2016|    4|        101|            101|   2|    Pleasure|     1961| 2016-04-01|   2016-08-25|\n",
      "+-----+-----------+--------------+-----------+-------------+----------+---------+--------------------+------+---+-------+------------+--------+----+-----+-----------+---------------+----+------------+---------+-----------+-------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+-----+-----------+--------------+-----------+-------------+----------+---------+--------------------+------+---+-------+------------+--------+----+-----+-----------+---------------+----+------------+---------+-----------+-------------+\n",
      "|cicid|arrivalPort|arrivalAddress|arrivalFlag|departureFlag|updateFlag|matchFlag|modeofTransportation|gender|age|airline|flightNumber|visaType|year|month|bornCountry|residentCountry|visa|i94visa_desc|birthYear|arrivalDate|departureDate|\n",
      "+-----+-----------+--------------+-----------+-------------+----------+---------+--------------------+------+---+-------+------------+--------+----+-----+-----------+---------------+----+------------+---------+-----------+-------------+\n",
      "|  7.0|        ATL|            AL|          G|         null|         Y|     null|                 Air|     M| 25|   null|       00296|      F1|2016|    4|        254|            276|   3|     Student|     1991| 2016-04-07|         null|\n",
      "| 15.0|        WAS|            MI|          T|            O|      null|        M|                 Air|     M| 55|     OS|       00093|      B2|2016|    4|        101|            101|   2|    Pleasure|     1961| 2016-04-01|   2016-08-25|\n",
      "| 16.0|        NYC|            MA|          O|            O|      null|        M|                 Air|  null| 28|     AA|       00199|      B2|2016|    4|        101|            101|   2|    Pleasure|     1988| 2016-04-01|   2016-04-23|\n",
      "+-----+-----------+--------------+-----------+-------------+----------+---------+--------------------+------+---+-------+------------+--------+----+-----+-----------+---------------+----+------------+---------+-----------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using the i94_df_select dataframe we will check how many i94ports are with XXX top 20\n",
    "i94_df_select.show(3) #excluding the XXX rows from the data\n",
    "i94_port_filter = i94_df_select.filter(~col('arrivalPort').isin('XXX')).show(3)\n",
    "#i94_port_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+--------------+-----------+-------------+----------+---------+--------------------+------+---+-------+------------+--------+----+-----+-----------+---------------+----+------------+---------+-----------+-------------+\n",
      "|cicid|arrivalPort|arrivalAddress|arrivalFlag|departureFlag|updateFlag|matchFlag|modeofTransportation|gender|age|airline|flightNumber|visaType|year|month|bornCountry|residentCountry|visa|i94visa_desc|birthYear|arrivalDate|departureDate|\n",
      "+-----+-----------+--------------+-----------+-------------+----------+---------+--------------------+------+---+-------+------------+--------+----+-----+-----------+---------------+----+------------+---------+-----------+-------------+\n",
      "|18.0 |NYC        |MI            |O          |O            |null      |M        |Air                 |null  |57 |AZ     |00602       |B1      |2016|4    |101        |101            |1   |Business    |1959     |2016-04-01 |2016-04-11   |\n",
      "|22.0 |NYC        |NY            |O          |O            |null      |M        |Air                 |null  |48 |AZ     |00608       |B1      |2016|4    |101        |101            |1   |Business    |1968     |2016-04-01 |2016-04-18   |\n",
      "|27.0 |BOS        |MA            |G          |O            |null      |M        |Air                 |M     |58 |LH     |00422       |B1      |2016|4    |101        |101            |1   |Business    |1958     |2016-04-01 |2016-04-05   |\n",
      "|28.0 |ATL        |MA            |G          |O            |null      |M        |Air                 |F     |56 |LH     |00422       |B1      |2016|4    |101        |101            |1   |Business    |1960     |2016-04-01 |2016-04-05   |\n",
      "|40.0 |CHI        |IL            |G          |O            |null      |M        |Air                 |M     |35 |OS     |00065       |B1      |2016|4    |101        |101            |1   |Business    |1981     |2016-04-01 |2016-04-10   |\n",
      "+-----+-----------+--------------+-----------+-------------+----------+---------+--------------------+------+---+-------+------------+--------+----+-----+-----------+---------------+----+------------+---------+-----------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using the i94_df_select dataframe we will check how many i94ports are with XXX top 20\n",
    "i94_port_filter_visatype_df = i94_df_select.filter(i94_df_select.visaType == \"B1\")\n",
    "i94_port_filter_visatype_df.show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|(arrivalPort = null)|  count|\n",
      "+--------------------+-------+\n",
      "|               false|3096313|\n",
      "+--------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_port_count_per_address_per_gender = i94_df_select.groupBy(i94_df_select.arrivalPort == \"null\").count()\n",
    "i94_port_count_per_address_per_gender.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+--------------+-----------+-------------+----------+---------+--------------------+------+---+-------+------------+--------+----+-----+-----------+---------------+----+------------+---------+-----------+-------------+\n",
      "|cicid|arrivalPort|arrivalAddress|arrivalFlag|departureFlag|updateFlag|matchFlag|modeofTransportation|gender|age|airline|flightNumber|visaType|year|month|bornCountry|residentCountry|visa|i94visa_desc|birthYear|arrivalDate|departureDate|\n",
      "+-----+-----------+--------------+-----------+-------------+----------+---------+--------------------+------+---+-------+------------+--------+----+-----+-----------+---------------+----+------------+---------+-----------+-------------+\n",
      "|  6.0|        XXX|          null|          T|         null|         U|     null|               other|  null| 37|   null|        null|      B2|2016|    4|        692|            692|   2|    Pleasure|     1979| 2016-04-29|         null|\n",
      "|  7.0|        ATL|            AL|          G|         null|         Y|     null|                 Air|     M| 25|   null|       00296|      F1|2016|    4|        254|            276|   3|     Student|     1991| 2016-04-07|         null|\n",
      "+-----+-----------+--------------+-----------+-------------+----------+---------+--------------------+------+---+-------+------------+--------+----+-----+-----------+---------------+----+------------+---------+-----------+-------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+------+-----------+--------------+--------+-----+\n",
      "|gender|arrivalPort|arrivalAddress|visaType|count|\n",
      "+------+-----------+--------------+--------+-----+\n",
      "|     F|        NYC|            NY|      WT|94406|\n",
      "|     F|        MIA|            FL|      B2|82402|\n",
      "|     M|        NYC|            NY|      WT|77390|\n",
      "|     M|        MIA|            FL|      B2|70432|\n",
      "|     F|        HHW|            HI|      WT|53793|\n",
      "|     F|        NYC|            NY|      B2|48254|\n",
      "|     M|        HHW|            HI|      WT|43853|\n",
      "|     F|        LOS|            CA|      WT|42361|\n",
      "|     M|        LOS|            CA|      WT|38661|\n",
      "|     M|        NYC|            NY|      B2|37915|\n",
      "|     F|        LOS|            CA|      B2|37338|\n",
      "|     F|        AGA|            GU|     GMT|34604|\n",
      "|     F|        MIA|            FL|      WT|30450|\n",
      "|     M|        LOS|            CA|      B2|30166|\n",
      "|  null|        MIA|            FL|      WT|29992|\n",
      "|     M|        AGA|            GU|     GMT|29970|\n",
      "|     M|        MIA|            FL|      WT|28891|\n",
      "|     F|        NEW|            NY|      WT|27447|\n",
      "|     F|        ORL|            FL|      WT|24756|\n",
      "|  null|        NYC|            NY|      WT|23224|\n",
      "+------+-----------+--------------+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "i94_df_select.show(2)\n",
    "i94_group_count = i94_df_select.groupBy(\"gender\",\"arrivalPort\",\"arrivalAddress\",\"visaType\").count().sort(F.desc(\"count\"))\n",
    "i94_group_count.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "<h3> Observation from above extracted information </h3>\n",
    "<h5><br> From the above result it is apparent that thre are 94K travelers with visatype as WT( a.k.a Temporary worker visa  and there port of entry is NYC  </br>\n",
    "</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Get the count per visa type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|count|\n",
      "+-----+\n",
      "|    4|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, countDistinct\n",
    "i94_df_get_count=i94_df_select.agg(countDistinct(col(\"gender\")).alias(\"count\")).sort(F.desc(\"count\"))\n",
    "i94_df_get_count.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "<h4>PYSPARK Data Transformations: We are transforming the mode of transportation\n",
    "    in our data frame as below:\n",
    "    Mode of transportation (1 = Air; 2 = Sea; 3 = Land; 9 = Not reported)</h4>\n",
    "    <h4>The value add of having this data transformed using case is to understand the\n",
    "    mode of transportation used while arriving at specific port</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+-------+\n",
      "|mode_of_transportation_desc|i94mode|\n",
      "+---------------------------+-------+\n",
      "|               Not Reported|    9.0|\n",
      "|                       Land|    3.0|\n",
      "|                        Sea|    2.0|\n",
      "|                        Air|    1.0|\n",
      "|                      other|   null|\n",
      "+---------------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mode of transportation (1 = Air; 2 = Sea; 3 = Land; 9 = Not reported)\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.sql.functions import expr \n",
    "i94_transform_mode_of_transportations = i94_df.withColumn(\"mode_of_transportation_desc\",expr(\"CASE WHEN i94mode == 1.0 THEN  'Air' WHEN i94mode == 2.0 THEN  'Sea' WHEN i94mode == 3.0 THEN  'Land' WHEN i94mode == 9.0 THEN  'Not Reported' ELSE 'other' END AS mode_of_transportation_desc\"))\n",
    "#i94_df.select(\"*\",expr(\"CASE WHEN i94mode == 1.0 THEN  'Air' WHEN i94mode == 2.0 THEN  'Sea' ELSE 'other' END AS value_desc\")).show()\n",
    "i94_transform_mode_of_transportations.select(['mode_of_transportation_desc','i94mode']).distinct().sort(col(\"i94mode\").desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### We will explore the most number of modes used to travel and from the below data it is apparent that \n",
    "#### maximum number of travelers using Air as their mode of transportation. \n",
    "#### In addition to the mode of transportation we are exploring to analyze the top 10 i94ports using the most #### preferred mode of transportation as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94_transform_mode_of_transportations_cnt = i94_transform_mode_of_transportations.groupby(['mode_of_transportation_desc']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Get the summary statistics (mean, standard deviance, min ,max, count) of \n",
    "#### numerical columns in a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94_df_withColum_transformation.describe().show(4).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Selecting few Fields from the above schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# select different occupations from I-94 dataset\n",
    "\n",
    "occupation_df= i94_df_withColum_transformation.select('occup').show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Observations: Occupations is mostly null or we can say missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Immigrations from different cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|i94mode|\n",
      "+-------+\n",
      "|   null|\n",
      "|    1.0|\n",
      "|    3.0|\n",
      "|    2.0|\n",
      "|    9.0|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cities_df = i94_df_withColum_transformation.select('mode').distinct()\n",
    "cities_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Find out different geneders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|gender|\n",
      "+------+\n",
      "|     F|\n",
      "|  null|\n",
      "|     M|\n",
      "|     U|\n",
      "|     X|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gender_df = i94_df.select('gender').distinct()\n",
    "gender_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>1377224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>1302743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>414269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X</td>\n",
       "      <td>1610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U</td>\n",
       "      <td>467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender    count\n",
       "0      M  1377224\n",
       "1      F  1302743\n",
       "2   None   414269\n",
       "3      X     1610\n",
       "4      U      467"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_cnt_df = i94_df.groupby('gender').count().sort(col(\"count\").desc())\n",
    "df_pandas_gender=gender_cnt_df.toPandas()\n",
    "df_pandas_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fde9bfdad30>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_pandas_gender.plot(kind='barh', x='gender', y='count', colormap='winter_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Observation : There are lot of missing values for geneder column From above count it is apparent \n",
    "# that there are more number of Male travles than femal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Get the total number of travelers per type of visa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visatype</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WT</td>\n",
       "      <td>1309059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B2</td>\n",
       "      <td>1117897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WB</td>\n",
       "      <td>282983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B1</td>\n",
       "      <td>212410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GMT</td>\n",
       "      <td>89133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F1</td>\n",
       "      <td>39016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>E2</td>\n",
       "      <td>19383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CP</td>\n",
       "      <td>14758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>E1</td>\n",
       "      <td>3743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I</td>\n",
       "      <td>3176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>F2</td>\n",
       "      <td>2984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>M1</td>\n",
       "      <td>1317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I1</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GMB</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>M2</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SBP</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CPL</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   visatype    count\n",
       "0        WT  1309059\n",
       "1        B2  1117897\n",
       "2        WB   282983\n",
       "3        B1   212410\n",
       "4       GMT    89133\n",
       "5        F1    39016\n",
       "6        E2    19383\n",
       "7        CP    14758\n",
       "8        E1     3743\n",
       "9         I     3176\n",
       "10       F2     2984\n",
       "11       M1     1317\n",
       "12       I1      234\n",
       "13      GMB      150\n",
       "14       M2       49\n",
       "15      SBP       11\n",
       "16      CPL       10"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visa_type_df = i94_df.groupby('visatype').count().sort(col(\"count\").desc())\n",
    "df_pandas=visa_type_df.toPandas()\n",
    "df_pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_pandas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-60e242efe223>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_pandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'barh'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'visatype'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolormap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'winter_r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_pandas' is not defined"
     ]
    }
   ],
   "source": [
    "df_pandas.plot(kind='barh', x='visatype', y='count', colormap='winter_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Observation : From the above count it has been observed that there are more number of travelers visiting for Tourism, vacation, pleasure visitor with Visa type as B2. There are 210K B1 visa travelers coming for business tours, there is one category with WT which has hight count as per above visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+-------+--------+-----+\n",
      "| i94yr|i94mon|gender|arrdate|visatype|count|\n",
      "+------+------+------+-------+--------+-----+\n",
      "|2016.0|   4.0|     F|20573.0|      WT|29799|\n",
      "|2016.0|   4.0|     M|20573.0|      WT|27670|\n",
      "|2016.0|   4.0|     F|20573.0|      B2|27200|\n",
      "|2016.0|   4.0|     F|20574.0|      WT|26536|\n",
      "|2016.0|   4.0|     F|20572.0|      B2|25705|\n",
      "|2016.0|   4.0|     F|20574.0|      B2|24814|\n",
      "|2016.0|   4.0|     M|20574.0|      WT|24174|\n",
      "|2016.0|   4.0|     F|20566.0|      B2|23714|\n",
      "|2016.0|   4.0|     F|20572.0|      WT|23648|\n",
      "|2016.0|   4.0|     F|20565.0|      B2|22833|\n",
      "|2016.0|   4.0|     F|20567.0|      WT|22370|\n",
      "|2016.0|   4.0|     F|20545.0|      WT|22345|\n",
      "|2016.0|   4.0|     M|20573.0|      B2|21956|\n",
      "|2016.0|   4.0|     F|20560.0|      WT|21885|\n",
      "|2016.0|   4.0|     F|20559.0|      B2|21843|\n",
      "|2016.0|   4.0|     F|20546.0|      WT|21757|\n",
      "|2016.0|   4.0|     F|20559.0|      WT|21616|\n",
      "|2016.0|   4.0|     F|20566.0|      WT|21572|\n",
      "|2016.0|   4.0|     F|20560.0|      B2|21518|\n",
      "|2016.0|   4.0|     F|20567.0|      B2|21470|\n",
      "+------+------+------+-------+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "year_mth_number_travelers_df = i94_df.groupby('i94yr','i94mon','gender','arrdate','visatype').count().sort(desc(\"count\")).show()\n",
    "year_mth_number_travelers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Most number of travelers traveled in the month of April."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239</td>\n",
       "      <td>152592</td>\n",
       "      <td>142457</td>\n",
       "      <td>...</td>\n",
       "      <td>3095921</td>\n",
       "      <td>138429</td>\n",
       "      <td>802</td>\n",
       "      <td>477</td>\n",
       "      <td>414269</td>\n",
       "      <td>2982605</td>\n",
       "      <td>83627</td>\n",
       "      <td>0</td>\n",
       "      <td>19549</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid  i94yr  i94mon  i94cit  i94res  i94port  arrdate  i94mode  i94addr  \\\n",
       "0      0      0       0       0       0        0        0      239   152592   \n",
       "\n",
       "   depdate    ...     entdepu  matflag  biryear  dtaddto  gender   insnum  \\\n",
       "0   142457    ...     3095921   138429      802      477  414269  2982605   \n",
       "\n",
       "   airline  admnum  fltno  visatype  \n",
       "0    83627       0  19549         0  \n",
       "\n",
       "[1 rows x 28 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find missing values\n",
    "from pyspark.sql.functions import isnull, when, count, col\n",
    "i94_missing_df = i94_df.select([count(when(isnull(c), c)).alias(c) for c in i94_df.columns]).toPandas()\n",
    "i94_missing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Loading World Temprature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "file_name = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "temperature_df = spark.read.csv(file_name, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1744-04-01</td>\n",
       "      <td>5.788</td>\n",
       "      <td>3.624</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1744-05-01</td>\n",
       "      <td>10.644</td>\n",
       "      <td>1.283</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1744-06-01</td>\n",
       "      <td>14.051</td>\n",
       "      <td>1.347</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1744-07-01</td>\n",
       "      <td>16.082</td>\n",
       "      <td>1.396</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1744-08-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0 1743-11-01               6.068                          1.737  Århus   \n",
       "1 1743-12-01                 NaN                            NaN  Århus   \n",
       "2 1744-01-01                 NaN                            NaN  Århus   \n",
       "3 1744-02-01                 NaN                            NaN  Århus   \n",
       "4 1744-03-01                 NaN                            NaN  Århus   \n",
       "5 1744-04-01               5.788                          3.624  Århus   \n",
       "6 1744-05-01              10.644                          1.283  Århus   \n",
       "7 1744-06-01              14.051                          1.347  Århus   \n",
       "8 1744-07-01              16.082                          1.396  Århus   \n",
       "9 1744-08-01                 NaN                            NaN  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  \n",
       "5  Denmark   57.05N    10.33E  \n",
       "6  Denmark   57.05N    10.33E  \n",
       "7  Denmark   57.05N    10.33E  \n",
       "8  Denmark   57.05N    10.33E  \n",
       "9  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: timestamp (nullable = true)\n",
      " |-- AverageTemperature: double (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: double (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temperature_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temperature_df.createOrReplaceTempView(\"GlobalLandTemperaturesByCity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# visualize missing values by columns \n",
    "temperature_df2 = temperature_df.withColumn(\"DATE\", F.split(\"dt\",' ').getItem(0))\\\n",
    "                                .withColumn(\"TIME\", F.split(\"dt\",' ').getItem(1))\\\n",
    "                                .withColumn(\"AverageTemprature\").cast(\"Double\")\n",
    "                                .drop(\"dt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AverageTemperature  AverageTemperatureUncertainty   City  Country Latitude  \\\n",
       "0               6.068                          1.737  Århus  Denmark   57.05N   \n",
       "1                 NaN                            NaN  Århus  Denmark   57.05N   \n",
       "2                 NaN                            NaN  Århus  Denmark   57.05N   \n",
       "3                 NaN                            NaN  Århus  Denmark   57.05N   \n",
       "4                 NaN                            NaN  Århus  Denmark   57.05N   \n",
       "\n",
       "  Longitude        DATE      TIME  \n",
       "0    10.33E  1743-11-01  00:00:00  \n",
       "1    10.33E  1743-12-01  00:00:00  \n",
       "2    10.33E  1744-01-01  00:00:00  \n",
       "3    10.33E  1744-02-01  00:00:00  \n",
       "4    10.33E  1744-03-01  00:00:00  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_df2.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------------------+-----------------------------+\n",
      "|      DATE|    TIME| AverageTemperature|AverageTemperatureUncertainty|\n",
      "+----------+--------+-------------------+-----------------------------+\n",
      "|1743-11-01|00:00:00|              6.068|           1.7369999999999999|\n",
      "|1743-12-01|00:00:00|               null|                         null|\n",
      "|1744-01-01|00:00:00|               null|                         null|\n",
      "|1744-02-01|00:00:00|               null|                         null|\n",
      "|1744-03-01|00:00:00|               null|                         null|\n",
      "|1744-04-01|00:00:00| 5.7879999999999985|           3.6239999999999997|\n",
      "|1744-05-01|00:00:00|             10.644|           1.2830000000000001|\n",
      "|1744-06-01|00:00:00| 14.050999999999998|                        1.347|\n",
      "|1744-07-01|00:00:00|             16.082|                        1.396|\n",
      "|1744-08-01|00:00:00|               null|                         null|\n",
      "|1744-09-01|00:00:00| 12.780999999999999|                        1.454|\n",
      "|1744-10-01|00:00:00|               7.95|                         1.63|\n",
      "|1744-11-01|00:00:00|  4.638999999999999|           1.3019999999999998|\n",
      "|1744-12-01|00:00:00|0.12199999999999987|                        1.756|\n",
      "|1745-01-01|00:00:00|-1.3330000000000002|                        1.642|\n",
      "|1745-02-01|00:00:00|             -2.732|                        1.358|\n",
      "|1745-03-01|00:00:00|              0.129|                        1.088|\n",
      "|1745-04-01|00:00:00|              4.042|                        1.138|\n",
      "|1745-05-01|00:00:00|               null|                         null|\n",
      "|1745-06-01|00:00:00|               null|                         null|\n",
      "+----------+--------+-------------------+-----------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temperature_df2.select([\"DATE\", \"TIME\",\"AverageTemperature\",\"AverageTemperatureUncertainty\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>364130</td>\n",
       "      <td>364130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dt  AverageTemperature  AverageTemperatureUncertainty  City  Country  \\\n",
       "0   0              364130                         364130     0        0   \n",
       "\n",
       "   Latitude  Longitude  \n",
       "0         0          0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing values from temprature data\n",
    "from pyspark.sql.functions import isnull, when, count, col\n",
    "nacounts = temperature_df.select([count(when(isnull(c), c)).alias(c) for c in temperature_df.columns]).toPandas()\n",
    "nacounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Temprature data has 360K records with AverageTemperature and AverageTempratureUncertainity not present\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "<h1> Airport Codes Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "file_name=\"airport-codes_csv.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "airport_codes_df = spark.read.csv(file_name,inferSchema=True, header=True, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>None</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>None</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>None</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>None</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00AS</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Fulton Airport</td>\n",
       "      <td>1100</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-OK</td>\n",
       "      <td>Alex</td>\n",
       "      <td>00AS</td>\n",
       "      <td>None</td>\n",
       "      <td>00AS</td>\n",
       "      <td>-97.8180194, 34.9428028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00AZ</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Cordes Airport</td>\n",
       "      <td>3810</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AZ</td>\n",
       "      <td>Cordes</td>\n",
       "      <td>00AZ</td>\n",
       "      <td>None</td>\n",
       "      <td>00AZ</td>\n",
       "      <td>-112.16500091552734, 34.305599212646484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00CA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Goldstone /Gts/ Airport</td>\n",
       "      <td>3038</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CA</td>\n",
       "      <td>Barstow</td>\n",
       "      <td>00CA</td>\n",
       "      <td>None</td>\n",
       "      <td>00CA</td>\n",
       "      <td>-116.888000488, 35.350498199499995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00CL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Williams Ag Airport</td>\n",
       "      <td>87</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CA</td>\n",
       "      <td>Biggs</td>\n",
       "      <td>00CL</td>\n",
       "      <td>None</td>\n",
       "      <td>00CL</td>\n",
       "      <td>-121.763427, 39.427188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00CN</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Kitchen Creek Helibase Heliport</td>\n",
       "      <td>3350</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CA</td>\n",
       "      <td>Pine Valley</td>\n",
       "      <td>00CN</td>\n",
       "      <td>None</td>\n",
       "      <td>00CN</td>\n",
       "      <td>-116.4597417, 32.7273736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name  elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport            11   \n",
       "1  00AA  small_airport                Aero B Ranch Airport          3435   \n",
       "2  00AK  small_airport                        Lowell Field           450   \n",
       "3  00AL  small_airport                        Epps Airpark           820   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport           237   \n",
       "5  00AS  small_airport                      Fulton Airport          1100   \n",
       "6  00AZ  small_airport                      Cordes Airport          3810   \n",
       "7  00CA  small_airport             Goldstone /Gts/ Airport          3038   \n",
       "8  00CL  small_airport                 Williams Ag Airport            87   \n",
       "9  00CN       heliport     Kitchen Creek Helibase Heliport          3350   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0        NA          US      US-PA      Bensalem      00A      None   \n",
       "1        NA          US      US-KS         Leoti     00AA      None   \n",
       "2        NA          US      US-AK  Anchor Point     00AK      None   \n",
       "3        NA          US      US-AL       Harvest     00AL      None   \n",
       "4        NA          US      US-AR       Newport     None      None   \n",
       "5        NA          US      US-OK          Alex     00AS      None   \n",
       "6        NA          US      US-AZ        Cordes     00AZ      None   \n",
       "7        NA          US      US-CA       Barstow     00CA      None   \n",
       "8        NA          US      US-CA         Biggs     00CL      None   \n",
       "9        NA          US      US-CA   Pine Valley     00CN      None   \n",
       "\n",
       "  local_code                              coordinates  \n",
       "0        00A       -74.93360137939453, 40.07080078125  \n",
       "1       00AA                   -101.473911, 38.704022  \n",
       "2       00AK              -151.695999146, 59.94919968  \n",
       "3       00AL    -86.77030181884766, 34.86479949951172  \n",
       "4       None                      -91.254898, 35.6087  \n",
       "5       00AS                  -97.8180194, 34.9428028  \n",
       "6       00AZ  -112.16500091552734, 34.305599212646484  \n",
       "7       00CA       -116.888000488, 35.350498199499995  \n",
       "8       00CL                   -121.763427, 39.427188  \n",
       "9       00CN                 -116.4597417, 32.7273736  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_codes_df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "airport = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"delimiter\", \",\").load(\"airport-codes_csv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|ident|         type|                name|elevation_ft|continent|iso_country|iso_region|municipality|gps_code|iata_code|local_code|         coordinates|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|  00A|     heliport|   Total Rf Heliport|          11|       NA|         US|     US-PA|    Bensalem|     00A|     null|       00A|-74.9336013793945...|\n",
      "| 00AA|small_airport|Aero B Ranch Airport|        3435|       NA|         US|     US-KS|       Leoti|    00AA|     null|      00AA|-101.473911, 38.7...|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airport.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "airport =   airport \\\n",
    "            .where(\n",
    "            (col(\"iso_country\") == \"US\") & (col(\"iata_code\").isNotNull()) & (col(\"type\").isin(\"large_airport\", \"medium_airport\", \"small_airport\"))) \\\n",
    "            .withColumn(\"isoRegion\", substring(col(\"iso_region\"), 4, 2)) \\\n",
    "            .drop(\"local_code\", \"elevation_ft\", \"iso_region\", 'continent') \\\n",
    "            .dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Airport data schema:\n",
      "root\n",
      " |-- ident: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      " |-- municipality: string (nullable = true)\n",
      " |-- gps_code: string (nullable = true)\n",
      " |-- iata_code: string (nullable = true)\n",
      " |-- coordinates: string (nullable = true)\n",
      " |-- isoRegion: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Airport data schema:\")\n",
    "airport.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FolderNameCheck:The _sas_data_air_port does exits...!! Using existing _sas_data_air_port\n",
      "Nothing went wrong\n"
     ]
    }
   ],
   "source": [
    "airport_table = airport.select(['ident', 'type', 'name', 'isoRegion', 'municipality','gps_code', 'iata_code','iso_country', 'coordinates']) \\\n",
    "               .dropDuplicates().dropna()\n",
    "parquet_check_n_create(\"_sas_data_air_port\",\"dim_air_port.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# U.S. City Demographic Data: Data Description\n",
    "## This data comes from OpenSoft and contains information about the demographics of all US ##cities and census-designated places with a population greater or equal to 65,000. ## Original data comes from the US Census Bureau's 2015 American Community Survey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "file_name = \"us-cities-demographics.csv\"\n",
    "demographics_df = spark.read.csv(file_name, inferSchema=True, header=True, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601</td>\n",
       "      <td>41862</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562</td>\n",
       "      <td>30908</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129</td>\n",
       "      <td>49500</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147</td>\n",
       "      <td>32935</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040</td>\n",
       "      <td>46799</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819</td>\n",
       "      <td>8229</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127</td>\n",
       "      <td>87105</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821</td>\n",
       "      <td>33878</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040</td>\n",
       "      <td>143873</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829</td>\n",
       "      <td>86253</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Peoria</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>33.1</td>\n",
       "      <td>56229</td>\n",
       "      <td>62432</td>\n",
       "      <td>118661</td>\n",
       "      <td>6634</td>\n",
       "      <td>7517</td>\n",
       "      <td>2.40</td>\n",
       "      <td>IL</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>1343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Avondale</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>29.1</td>\n",
       "      <td>38712</td>\n",
       "      <td>41971</td>\n",
       "      <td>80683</td>\n",
       "      <td>4815</td>\n",
       "      <td>8355</td>\n",
       "      <td>3.18</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>11592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>West Covina</td>\n",
       "      <td>California</td>\n",
       "      <td>39.8</td>\n",
       "      <td>51629</td>\n",
       "      <td>56860</td>\n",
       "      <td>108489</td>\n",
       "      <td>3800</td>\n",
       "      <td>37038</td>\n",
       "      <td>3.56</td>\n",
       "      <td>CA</td>\n",
       "      <td>Asian</td>\n",
       "      <td>32716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>O'Fallon</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>36.0</td>\n",
       "      <td>41762</td>\n",
       "      <td>43270</td>\n",
       "      <td>85032</td>\n",
       "      <td>5783</td>\n",
       "      <td>3269</td>\n",
       "      <td>2.77</td>\n",
       "      <td>MO</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>2583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>High Point</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>35.5</td>\n",
       "      <td>51751</td>\n",
       "      <td>58077</td>\n",
       "      <td>109828</td>\n",
       "      <td>5204</td>\n",
       "      <td>16315</td>\n",
       "      <td>2.65</td>\n",
       "      <td>NC</td>\n",
       "      <td>Asian</td>\n",
       "      <td>11060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City           State  Median Age  Male Population  \\\n",
       "0     Silver Spring        Maryland        33.8            40601   \n",
       "1            Quincy   Massachusetts        41.0            44129   \n",
       "2            Hoover         Alabama        38.5            38040   \n",
       "3  Rancho Cucamonga      California        34.5            88127   \n",
       "4            Newark      New Jersey        34.6           138040   \n",
       "5            Peoria        Illinois        33.1            56229   \n",
       "6          Avondale         Arizona        29.1            38712   \n",
       "7       West Covina      California        39.8            51629   \n",
       "8          O'Fallon        Missouri        36.0            41762   \n",
       "9        High Point  North Carolina        35.5            51751   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0              41862             82463                1562         30908   \n",
       "1              49500             93629                4147         32935   \n",
       "2              46799             84839                4819          8229   \n",
       "3              87105            175232                5821         33878   \n",
       "4             143873            281913                5829         86253   \n",
       "5              62432            118661                6634          7517   \n",
       "6              41971             80683                4815          8355   \n",
       "7              56860            108489                3800         37038   \n",
       "8              43270             85032                5783          3269   \n",
       "9              58077            109828                5204         16315   \n",
       "\n",
       "   Average Household Size State Code                               Race  Count  \n",
       "0                    2.60         MD                 Hispanic or Latino  25924  \n",
       "1                    2.39         MA                              White  58723  \n",
       "2                    2.58         AL                              Asian   4759  \n",
       "3                    3.18         CA          Black or African-American  24437  \n",
       "4                    2.73         NJ                              White  76402  \n",
       "5                    2.40         IL  American Indian and Alaska Native   1343  \n",
       "6                    3.18         AZ          Black or African-American  11592  \n",
       "7                    3.56         CA                              Asian  32716  \n",
       "8                    2.77         MO                 Hispanic or Latino   2583  \n",
       "9                    2.65         NC                              Asian  11060  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the first five records\n",
    "demographics_df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 5: Complete Project Write Up\n",
    "#### Rationale for the choice of tools and technologies for the project\n",
    "        1. Apache spark was used because of:\n",
    "        it's ability to handle multiple file formats with large amounts of data.\n",
    "        Apache Spark offers a lightning-fast unified analytics engine for big data.\n",
    "        Spark has easy-to-use APIs for operating on large datasets\n",
    "        In addition to the above we can make use of Arrow for memory management\n",
    "        2. Code readability,maintainability and familiarity is better with python as compare to Scala\n",
    "        3. More Mature and time tested regarding data analytics and statistical libraries like numpy pandas, matplotlib and scikit-learn\n",
    "        \n",
    "        For the general purpose programming python is observed to be best option which can work \n",
    "        along with pyspark. \n",
    "        Note : Apache Spark might have memory limitations if the cluster size is not adequet in such         a cases using the AWS autoscaling during the processing might be the good solution.\n",
    "        Propose how often the data should be updated and why.The current I94 immigration data is \n",
    "        updated Monthly however having it daily updated with incremental processing will help in reducing the full volume load every month\n",
    "        \n",
    "### Write a description of how you would approach the problem differently under the following scenarios:\n",
    "   1. If the data loads are incremental the daily records processing incrementally will help in getting the less overhead due to applying the Type-2 processing and since daily processing may not invovle huge volume of data due to only considering the records for current day travelled travelers.\n",
    "   2. For efficient storage we can make use of S3 buckets with Standard type, In addition the most recent data can be arived on S3 buckets and least frequently data can be moved to Infrequent accessed storage.\n",
    "   3. In addition to the above we can also make use of AWS services such as AWS Redshift for ETL loads using the AWS Elasticache for analytical use.\n",
    "   4. Test-driven approach is very useful in these scenarios\n",
    "   5. Using broadcasting for the SMALL tables when joining with LARGE tables to each/machine node when you perform join df.join(broadcast(),[],how=left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
